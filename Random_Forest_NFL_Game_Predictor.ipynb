{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaveshasasik/nfl_game_predictor/blob/main/Random_Forest_NFL_Game_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Function to find most impactful running back\n",
        "def calculate_top_rb_impact(file_path):\n",
        "    # Load data\n",
        "    data = pd.read_csv(file_path, header=1)\n",
        "\n",
        "    # Rename columns for easy access\n",
        "    data.columns = [\n",
        "        'Rk', 'Player', 'Tm', 'Age', 'Pos', 'G', 'GS', 'Att', 'Yds', 'TD',\n",
        "        '1D', 'Succ%', 'Lng', 'Y/A', 'Y/G', 'Fmb'\n",
        "    ]\n",
        "\n",
        "    # Filter for running backs with minimum attempts\n",
        "    data = data[(data['Pos'] == 'RB') & (data['Att'] >= 60)]\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    data['Yards_per_Attempt'] = data['Yds'] / data['Att']\n",
        "    data['Touchdowns_per_Attempt'] = data['TD'] / data['Att']\n",
        "    data['Success_Rate'] = data['Succ%'] / 100  # Assuming Succ% is already a percentage\n",
        "\n",
        "    # Select metrics and normalize\n",
        "    metrics = ['Yards_per_Attempt', 'Touchdowns_per_Attempt', 'Success_Rate', 'Y/G']\n",
        "    scaler = MinMaxScaler()\n",
        "    data[metrics] = scaler.fit_transform(data[metrics])\n",
        "\n",
        "    # Calculate impact score\n",
        "    data['Impact_Score'] = (\n",
        "        0.4 * data['Yards_per_Attempt'] +\n",
        "        0.3 * data['Touchdowns_per_Attempt'] +\n",
        "        0.2 * data['Success_Rate'] +\n",
        "        0.1 * data['Y/G']\n",
        "    )\n",
        "\n",
        "    # Get top player per team\n",
        "    top_players_per_team = (\n",
        "        data.sort_values(by=['Tm', 'Impact_Score'], ascending=[True, False])\n",
        "        .groupby('Tm')\n",
        "        .head(1)\n",
        "    )\n",
        "\n",
        "    # Return impactful players as a dictionary with team names\n",
        "    impactful_players = {\n",
        "        row['Tm']: {\n",
        "            'Position': row['Pos'],\n",
        "            'Player': row['Player'],\n",
        "            'Impact_Score': row['Impact_Score']\n",
        "        }\n",
        "        for _, row in top_players_per_team.iterrows()\n",
        "    }\n",
        "\n",
        "    return impactful_players\n",
        "\n",
        "\n",
        "# Function to process general team data (standings and win/loss records)\n",
        "def process_team_standings(file_path):\n",
        "    # Load data\n",
        "    standings = pd.read_csv(file_path)\n",
        "\n",
        "    # Calculate win percentage\n",
        "    standings['Win_Percentage'] = standings['Wins'] / (standings['Wins'] + standings['Losses'])\n",
        "\n",
        "    # Normalize win percentage\n",
        "    scaler = MinMaxScaler()\n",
        "    standings['Win_Percentage_Normalized'] = scaler.fit_transform(standings[['Win_Percentage']])\n",
        "\n",
        "    # Return standings data\n",
        "    team_data = standings[['Team', 'Win_Percentage_Normalized']].set_index('Team').to_dict('index')\n",
        "    return team_data\n",
        "\n",
        "# Combine impact scores and general team data\n",
        "def combine_team_data(rb_impact_data, team_data):\n",
        "    combined_data = []\n",
        "    for team, rb_info in rb_impact_data.items():\n",
        "        if team in team_data:\n",
        "            combined_data.append({\n",
        "                'Team': team,\n",
        "                'Impact_Score': rb_info['Impact_Score'],\n",
        "                'Win_Percentage': team_data[team]['Win_Percentage_Normalized']\n",
        "            })\n",
        "    return pd.DataFrame(combined_data)\n",
        "\n",
        "\n",
        "def calculate_team_impact_scores(players_dict):\n",
        "    # Define arbitrary weights for each position\n",
        "    position_weights = {\n",
        "        \"QB\": 1.5,    # Quarterback\n",
        "        \"WR\": 1.2,    # Wide Receiver\n",
        "        \"TE\": 1.1,    # Tight End\n",
        "        \"RB\": 1.0,    # Running Back\n",
        "        \"SFT\": 0.9,   # Safety\n",
        "        \"CB/LB\": 0.8  # Cornerback/Linebacker\n",
        "    }\n",
        "\n",
        "    # Initialize a dictionary to store team impact scores\n",
        "    team_impact_scores = {}\n",
        "\n",
        "    # Iterate over each team in the dictionary\n",
        "    for team, players in players_dict.items():\n",
        "        team_score = 0  # Initialize team score\n",
        "\n",
        "        # Calculate weighted score for each player's position\n",
        "        for pos, player, impact_score in players:\n",
        "            weight = position_weights.get(pos, 1)  # Default weight is 1 if position not found\n",
        "            team_score += impact_score * weight  # Add weighted impact score\n",
        "\n",
        "        # Store the total impact score for the team\n",
        "        team_impact_scores[team] = team_score\n",
        "\n",
        "    return team_impact_scores\n",
        "\n",
        "\n",
        "\n",
        "# Random forest model\n",
        "def train_random_forest(data):\n",
        "    # Prepare features and labels\n",
        "    X = data[['Impact_Score', 'Win_Percentage']]\n",
        "    y = data['Outcome']  # Binary outcome: 1 = Win, 0 = Loss\n",
        "\n",
        "    # Train random forest\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "    rf.fit(X, y)\n",
        "\n",
        "    return rf\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Calculate RB impact\n",
        "    rb_file_path = '2023_rushing_stats.csv'  # Path to rushing stats file\n",
        "    rb_impact = calculate_top_rb_impact(rb_file_path)\n",
        "    print(\"RB Impact:\", rb_impact)\n",
        "\n",
        "    # Process team standings\n",
        "    standings_file_path = 'team_standings.csv'  # Path to standings file\n",
        "    team_standings = process_team_standings(standings_file_path)\n",
        "    print(\"Team Standings:\", team_standings)\n",
        "\n",
        "    # Combine data\n",
        "    combined_data = combine_team_data(rb_impact, team_standings)\n",
        "    print(\"Combined Data:\", combined_data)\n",
        "\n",
        "    # Train random forest (assuming Outcome column is present in combined_data)\n",
        "    rf_model = train_random_forest(combined_data)\n",
        "    print(\"Random Forest Model Trained.\")\n"
      ],
      "metadata": {
        "id": "Ek-okcV-PMUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}